'''
R&T generation de cartes d'occupation des sols par reseaux de neurones convolutionnels

Data preparation for Keras exploitation. 

Requirement: the raster annotations must have been generated prior to launch this script. 
             You can run the script data_formatting_10m with standard settings to obtain these annotations.
Inputs:
    - Directory containing Sentinel2 images

Processing:
    - Finds and stores the min and max values of each channel for each tile, used for normalization purposes in the deep learning process.
      Please note that min and max are now replaced by percentiles to avoid extreme values generated by outliers.
    - The list of pixels containing valid annotations for a given class. This format speeds up patch generation in the learning process

Outputs:
    - the min and max values for each channel of each tile stored as a numpy array
    - a dictionnary of valid annotations for each class of each tile, stored as a pickle object.

Execution example:
python Sentinel2_prepare_data.py -img /work/OT/siaa/Work/RTDLOSO/data/feat_S2_20152016_extract -label /work/OT/siaa/Work/RTDLOSO/data/feat_S2_20152016_extract/RasterData -out /work/OT/siaa/Work/RTDLOSO/data/feat_S2_20152016_extract/

Author : CÃ©line Craye (2017), Thales Services
'''

import numpy as np
import os
import time
import sys
import glob
import gdal
import gdalconst
import pickle
import argparse


in_notebook = False
try:
    get_ipython
    in_notebook = True
except:
    print("Running in terminal...")
    
def get_tilename_list(s_img_dir):
    '''
    get the list of images in the input directory
    @param s_img_dir: input directory
    @return t_img: list of input images
    '''
    t_img = sorted(glob.glob(os.path.join(s_img_dir, 'T?????')))
    for i in range(len(t_img)):
        t_img[i] = t_img[i].replace(s_img_dir + '/','')
    if len(t_img) == 0:
        raise Exception('Error, no image found in {}'.format(s_img_dir))
    return t_img

def get_image_list(s_img_dir):
    '''
    get the list of images in the input directory
    @param s_img_dir: input directory
    @return t_img: list of input images
    '''
    t_img = sorted(glob.glob(os.path.join(s_img_dir, 'T?????/*.tif')))
    if len(t_img) == 0:
        raise Exception('Error, no image found in {}'.format(s_img_dir))
    return t_img

def load_tif_to_nparray(tif_path):
    o_image = gdal.Open(tif_path)
    if o_image is None:
        raise Exception("couldn't open input dataset" + tif_path)

    o_proj = o_image.GetProjection()
    o_geo = o_image.GetGeoTransform()
    t_img = o_image.ReadAsArray()
    o_image = None
    return t_img

def raster_to_2D_array(s_img, u_band):
    '''
    create a 2D numpy array from a raster image. Output array shape is : (nb_row, nb_col)
    @param s_img: multi-band input image
    @param u_band: number of band to extract (starting from 1)
    @return t_img: numpy array corresponding to the input image, shape : (nb_row, nb_col)
    '''
    o_image = gdal.Open(s_img)
    if o_image is None:
        print("couldn't open input dataset {0}".format(s_img))
        sys.exit(1)
    u_nb_col = o_image.RasterXSize
    u_nb_row = o_image.RasterYSize
    o_band = o_image.GetRasterBand(u_band)
    t_img = np.array(o_band.ReadAsArray(0, 0, u_nb_col, u_nb_row))
    o_image = None
    return t_img


def main():
    '''
    main
    '''
    # Parser creation
    parser = argparse.ArgumentParser(description='Sentinel2 data preparation for deep learning')
    # Args
    parser.add_argument('-img', '--img', metavar='[IMG_DIR]', help='Sentinel2 image directory', required=True)
    parser.add_argument('-label', '--label', metavar='[LABEL]',\
                        help='Directory containing for each tile training.tif and testing.tif', required=True)
    parser.add_argument('--skipMinMax', help='Skip min/max computation', action="store_true")
    parser.add_argument('--skipValid', help='Skip valid pixel computation', action="store_true")
    parser.add_argument('-out', '--out', metavar='[OUT]', help='Output directory', required=True)
    # Command line parsing
    args = vars(parser.parse_args())
    s_img_dir = os.path.abspath(args['img'])
    s_label = os.path.abspath(args['label'])
    s_out = os.path.abspath(args['out'])
    os.system('mkdir -p {0}'.format(s_out))
    
    
    # get images and ground truth directories.
    t_img_list = get_image_list(s_img_dir)
    t_tilename_list = get_tilename_list(s_img_dir)
    t_gt_list = sorted(glob.glob(os.path.join(s_label, '*label_training.tif')))

    if not args['skipMinMax']:
        print("Computing min/max for tiles...")
        # for each tile, get and save min an max values of each channel
        for i in range(len(t_img_list)):
            print(t_tilename_list[i])
            print("reading " + t_img_list[i])
            o_image = gdal.Open(t_img_list[i])
            NUM_BANDS = o_image.RasterCount
            o_image = None
            min_channels = np.zeros((NUM_BANDS))
            max_channels = np.zeros((NUM_BANDS))
            img = None
            img = load_tif_to_nparray(t_img_list[i])
            print(img.shape)
            for j in range(NUM_BANDS):
                #print("band " + str(j) + "/" + str(NUM_BANDS))
                min_channels[j] = np.percentile(img[j,...],3)
                max_channels[j] = np.percentile(img[j,...],97)
            min_channels_str = os.path.join(s_out,  t_tilename_list[i], t_tilename_list[i] + '_min_channels')
            max_channels_str = os.path.join(s_out,  t_tilename_list[i], t_tilename_list[i] + '_max_channels')
            print(min_channels_str)
            print(max_channels_str)
            np.save(min_channels_str,min_channels)
            np.save(max_channels_str, max_channels)  
    if not args['skipValid']:
        # get list of valid pixels for each tile, each class
        print("Computing valid positions for tiles...")
        for i in range(len(t_gt_list)):
            loc_list = {}
            t_gt = load_tif_to_nparray(t_gt_list[i])
            print("loading file " + t_gt_list[i])
            print(t_gt.shape)
            print("loading file " + t_img_list[i])
            t_band = raster_to_2D_array(t_img_list[i], 1)
            print(t_band.shape)
            # for each class
            for j in range(1,256):
                class_pix_list = np.where((t_gt == j) & (t_band != 0))
                if len(class_pix_list[0]) > 0:
                    loc_list[j] = class_pix_list
            out_filename = t_gt_list[i] + '_valid_pos.pickle'
            #out_filename = out_filename.replace(s_label, s_out)
            out_filename = out_filename.replace('.tif', '')
            with open(out_filename, 'wb') as handle:
                print("saving file " + out_filename)
                pickle.dump(loc_list, handle, protocol=pickle.HIGHEST_PROTOCOL)


if __name__ == '__main__':
    main()
